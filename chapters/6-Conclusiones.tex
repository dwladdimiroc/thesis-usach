\chapter{Conclusiones}
\label{cap:conclusiones}
Dentro del trabajo realizado, se propuso sistema de distribución de carga dinámico que permita una mejor utilización de recursos y con ello un aumento en su capacidad de procesamiento. Debo a esto, se procesa mayor cantidad de información, lo cual es relevante para las aplicaciones soportadas por el SPS, puesto que mejora la precisión de los resultados entregados.

\section{Detalles de la contribución}
Las contribuciones realizadas en este trabajo se encuentra el diseño e implementación de un sistema de distribución de carga que pudiera lidiar con el dinamismo del flujo de un SPS. En este sistema, se diseñaron cuatro módulos, los cuales estaban compuestos por un módulo de monitoreo, que estuviera recolectando las estadísticas necesarios para el funcionamiento de un módulo reactivo y predictivo.

Estos últimos módulos fueron diseñados e implementados con un algoritmo reactivo y predictivo respectivamente, donde estos pudieran determinar el estado del operador según la tarea que tuvieran asignada. Por parte del reactivo, su misión era analizar en el momento la carga del operador, cumpliendo así el primer objetivo de este trabajo. Y por parte del predictivo, era estimar la carga del operador, cumpliendo el segundo objetivo.

Así mismo, se diseño e implementó un sistema de distribución de carga, que tuviera un módulo de administración de carga, donde éste se encargaba de administrar la cantidad de réplicas de los operadores del SPS de forma elástica. Para esto, se diseño e implementó un algoritmo de administración de carga, cumpliendo así el tercer objetivo del trabajo presente.

Por otra parte, se diseñaron y construyeron distintos experimentos que permitieran validar la hipótesis planteada, cuyo planteamiento era la utilización de sistema de distribución de carga, de tal manera que mejore el rendimiento del SPS y se procese mayor cantidad de eventos.

Y finalmente, se evaluó y analizó el rendimiento del sistema a través de distintas aplicaciones generadas sobre un SPS, para lo cual se utilizó S4. En todas las aplicaciones se mostraron mejoras de la cantidad de eventos procesados, dependiendo del tipo de aplicación se detectó un aumento de hasta 8 veces más eventos procesados. Como se había mencionado anterior, al poseer mayor cantidad de datos procesados, se posee mayor precisión en la información obtenida. Por otra parte, el costo asociado por la implementación del sistema de distribución de carga, fue de un aumento de $0,0119\%$, pero con una disminución del uso de la memoria RAM, la cual fue de un $1,5187\%$, lo cual significa que el sistema si bien puede aumentar el consumo de CPU, disminuye el uso de la RAM, lo cual significa que puede disminuirse la cantidad de memoria RAM asociada a un computador. Por ejemplo, en el caso que se utilice un \textit{Cloud}, las máquinas virtuales que se deben configurar, pueden configurarse con menor cantidad de memoria RAM, lo cual abarata los costos asociados a la aplicación.

Por lo que no sólo se lograron todos los objetivos planteados, sino que se demostró la hipótesis planteada en el inicio del trabajo, donde según los distintos experimentos realizados, se determinó que el sistema cumplía una mejora en el SPS, aumentando la cantidad de datos procesados. Pero además de esto, se concluyó que el sistema poseía un bajo costo de implementación, poseyendo además ganancias en el consumo de memoria.

\section{Discusiones}

Uno de los problemas a destacar fue la implementación realizada en S4, debido que el SPS poseía ciertas falacias para implementar los algoritmos diseñados. Esto se debía que la cantidad de eventos entrantes, no eran todos procesados, independiente si se generaba una mayor cantidad de réplicas. Este problema fue detectado en la fase de experimentación, donde al tratar de realizar pruebas con un tiempo de ejecución mayor, existía una disminución considerablemente de la tasa de rendimiento de un operador, dado que el \textit{buffer} del operador se llena al no procesar todos los datos entrantes, bloqueando el envío de eventos a éste.

Dentro de las limitaciones del trabajo estaba la homogeneidad de los eventos procesados, esto estaba pensando de tal manera que la tasa de procesamiento fuera similar para cada uno de los eventos entrantes. Esto era importante a considerar, porque de ser heterogéneos los eventos entrantes, existía un problema con la tasa de procesamiento, debido que se debía considerar un promedio de ésta según lo calculado en la ventana de tiempo anterior a la analizada. Pero, esto no garantiza que los próximos eventos posean la misma tasa de procesamiento, debido que podría darse el caso que su tasa de procesamiento sea más alta, por lo que el cálculo de la tasa de rendimiento sería errónea. Debido a esto, es que se consideran datos homogéneos, de tal manera que pueda encontrase una tasa de procesamiento estable para el sistema, y no encontrar ambigüedades en los cálculos realizados.

Si bien el trabajo realizado hace un buen análisis del sistema lógico, no realiza un buena análisis según los recursos disponibles por parte del sistema. Es por esto, que tuvo que limitarse la cantidad de operadores que podían replicarse, dado que no existen recursos ilimitados en la máquina. Por lo tanto, puede generarse ahora otro tipo de sobrecarga, que ya no es a nivel lógico, sino físico, para lo cual el sistema no está diseñado.

Por otra parte, el sistema no detecta patrones estacionarios que puedan existir en el día, lo cual es una desventaja en la implementación del sistema. Esto se debe a que el algoritmo predictivo analiza procesos estocásticos, y no un aprendizaje del comportamiento del flujo de datos, como lo realizan así modelos predictivos como \textit{machine learning} \citep{bookMohri2012}.

Pero independiente de las limitantes o desventajas existentes, el sistema diseñado posee la ventaja de poseer un bajo cómputo en el cálculo de los distintos algoritmos diseñados, teniendo un bajo \textbf{overhead} de implementación. También se destaca el rápido análisis de los operadores, ya sea en la distribución de carga en cada uno de los operadores, o en el estado que se encuentra el operador, de tal manera de modificar la cantidad de réplicas existentes. De esta manera, al poseer un sistema elástico, se posee la ventaja de optimizar la cantidad de recursos existentes y adquirir un dinamismo en el grafo de la aplicación ejecutada sobre el SPS.

\section{Trabajo futuro}
Dentro de las mejoras que se puede realizar al sistema son fundamental tres: un sistema de distribución de carga que trabaje con más de un nodo físico, un predictor que indique dinámicamente cuantas son las réplicas necesarias según el historial y la implementación del sistema diseñado en otro SPS.

En el primer caso, se podría realizar un sistema de monitoreo, en el cual se posea una máquina para analizar los datos de cada una de las máquinas disponibles, y ésta posea además las réplicas primarias de cada operador. En caso que exista una sobrecarga por parte de un operador, es necesario realizar una réplica por parte del monitor centralizado, y que este determine a cual de las máquinas disponibles debe enviar los datos según la cantidad de recursos disponibles, tasa de procesamiento por parte del operador, entre otras variables. De esta manera, se posee un sistema escalable, debido que se puede implementar un SPS en un servicio de \textit{Cloud Computing}, de tal manera que en caso que sea necesario mayor cantidad de máquinas, se añadan y el monitor pueda distribuir mayor carga a estas nuevas máquinas, en caso de ser requerido.

En el segundo caso, se podría realizar un análisis más detallado de la historia, de tal manera que según el comportamiento que éste posea, indica cuantas son las réplicas que se desean aumentar o disminuir según su historia. Por ejemplo, en el caso que la tasa de rendimiento sea muy alta en la historia, significa que posee una gran cantidad de réplicas, pero si la tasa de rendimiento es alta, pero no excesivamente, la cantidad de réplicas debe ser menor. En el caso propuesto, se realizó con valores constantes, por lo que podría generarse una mejora a futuro con este tipo de análisis.

Así mismo, se podría realizar un estudio respecto a \textit{peak} que se encuentren de forma estacionaria según cierto flujo de datos, y que el sistema se adapte dinámicamente a esos \textit{peak}. Por ejemplo, en el caso de \textit{Twitter} existen períodos del día que los usuarios comentan más, por lo tanto, en esos períodos aumentar la cantidad de recursos, y en los períodos que no comentan tanto, se podría disminuir la cantidad de recursos, por lo que se podría evaluar alternativas para el predictor como \textit{machine learning} \citep{bookMohri2012}.

Finalmente, el tercer caso, es poder implementar el sistema de distribución de carga en otro SPS, ya sea Storm \citep{stormtwitter} o StreamIt \citep{ThiesKA02}, debido a los distintos problemas que surgieron al utilizar el S4. De esta manera, se podría realizar una comparación de cual son los distintos pro y contra de los SPS con el sistema implementando, y en que casos es mejor utilizar uno u otro.