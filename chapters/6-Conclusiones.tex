\chapter{Conclusiones}
\label{cap:conclusiones}

Dentro del trabajo realizado se encontraron distintas dificultades para poder realizar los experimentos como se deseaban, entre ellas el motor de procesamiento de \textit{stream} S4. Si bien se escogió este SPS debido al apoyo en el ambiente de trabajo que se poseía, independiente que se encontrara descontinuado y obsoleto, el trabajo a bajo nivel que se realizó conllevó a encontrar errores en la programación del sistema en las cuales no existía apoyo técnico. Una de ellas, era la sincronización de los procesamientos de cada uno de los operadores al llevar sus mensajes, los cuales eran almacenados en una cola finita. Esta cola se volvió un problema, debido que S4 no tenía un sistema de purgamiento, lo cual significa que la cola seguía con eventos ya procesados, por lo que después de cierto período la cantidad de datos procesados disminuida considerablemente. Esto impidió que se pueda realizar experimentos con mayor cantidad de tiempo, pero no significó que el sistema realizado estuviera erróneo, sino que el sistema donde se implementó no fue el indicado.

Una de las situaciones importantes a destacar, fue la cantidad de código que se tuvo que modificar en S4, debido a problemas de implementación del sistema propuesto, dado el funcionamiento de este SPS. Uno de ellos fue la forma en que interactúa la fuente de datos, denominada \textit{adapter} en S4, y los operadores del sistema. Por lo que se tuvo que realizar una sincronización por parte de estos dos entes, los cuales según el funcionamiento de S4 deben estar en dos máquinas distintas, aunque se puede ejecutar en la misma máquina, éste considera que son dos sistemas diferentes. Esto fue necesario para notificar al sistema que el \textit{adapter} estaba disponible, y el sistema de distribución de carga puede empezar a funcionar, y para informar de los cambios ocurridos por parte de la fuente de datos respecto a los operadores que enviará información.

Otro de las situaciones importantes a analizar el valor que tomaba la tasa de procesamiento ($\mu$), debido que esta podía ir variando con el transcurso del tiempo. Por ejemplo, si se posee un flujo de datos heterogéneos, puede suceder el caso que en cierto período de tiempo los datos posean mayor tiempo de procesamiento, por lo tanto la tasa de procesamiento disminuye. Por lo tanto, surge un análisis engañoso de los datos, debido que si en períodos de tiempo, se analiza su tasa de procesamiento, no indica que en el próximo período siga con el mismo comportamiento, por lo tanto, eso puede significar que existen tomas de decisiones erróneas según el comportamiento de los datos. Es decir, si consideramos que según un período de tiempo calculamos su tasa de procesamiento, y en el próximo período utilizamos esa tasa como referencia, puede ser que los datos no sean del mismo tiempo de procesamiento que los anteriores, lo cual genera un mal análisis del comportamiento del sistema. Debido a esto, es que se consideran datos homogéneos, de tal manera que pueda encontrase una tasa de procesamiento estable para el sistema, y no encontrar ambigüedades en los cálculos realizados.

Dentro de las conclusiones que se puede realizar respecto al trabajo realizado, es que es un sistema que posee un buen análisis del sistema lógico, debido a las estadísticas obtenidas por parte del sistema, pero no analiza la cantidad de recursos disponibles por parte de la máquina, lo cual es una desventaja considerable, a excepción que se posea un supercomputador. Esto se presenta, debido que al momento de replicar, se utiliza a distribuir la carga en el computador, pero esto no significa que la máquina pueda tener una sobrecarga a futuro debido al alto nivel de procesamiento que posee, es por esto que en el diseño se específico un límite en la cantidad de réplicas que pueden realizarse.

Pero independiente de su desventaja, posee varias ventajas debido al bajo cómputo que se posee por parte de los cálculos realizados, tanto por el algoritmo reactivo como predictivo, siendo bajo el \textit{overhead} existente y una rápida respuesta del estado de cada operador. También es importante destacar el simple y rápido análisis de los datos, ya sea la distribución de la carga en cada uno de los operadores o en la forma en que se determina si un operador posee sobrecarga o no, como también la disminución de sus réplicas en caso que este ocioso. El comportamiento elástico que posee el sistema es una gran ventaja, debido a la optimización de los recursos y al dinamismo que se posee en este.

\section{Trabajo futuro}

Dentro de las mejores que se puede realizar por parte del sistema son fundamental dos: sistema de distribución que soporte más de una máquina y el predictor que dinamicamente se adapte al historial realizado.

En el primer caso, se podría realizar un sistema de monitoreo, en el cual se posea una máquina se analiza los datos de cada una de las máquinas disponibles, y ésta posea además las réplicas primarias de cada operador. En caso que exista una sobrecarga por parte de un operador, es necesario realizar una réplica por parte del monitor centralizado, y que este determine a cual de las máquinas disponibles debe enviar los datos según la cantidad de recursos disponibles, tasa de procesamiento por parte del operador, entre otras variables. De esta manera, se posee un sistema escalable, debido que se puede implementar un SPS en un servicio de \textit{Cloud Computing}, de tal manera que en caso que sea necesario mayor cantidad de máquinas, se añadan y el monitor pueda distribuir mayor carga a estas nuevas máquinas, en caso de ser requerido.

En el segundo caso, se podría realizar un análisis más detallado de la historia, de tal manera que según el comportamiento que éste posea indica cuanta son las réplicas que se desean aumentar o disminuir según su historia. Por ejemplo, en el caso que la tasa de rendimiento sea muy alta en la historia, significa que posee una gran cantidad de réplicas, pero si la tasa de rendimiento es alta, pero no excesivamente, la cantidad de réplicas debe ser menor. En el caso propuesto, se realizó con valores constantes, por lo que podría generarse una mejora a futuro con este tipo de análisis.

Así mismo, se podría realizar un estudio respecto a \textit{peak} que se encuentren de forma estacionaria según cierto flujo de datos, y que el sistema se adapte dinámicamente a esos \textit{peak}. Por ejemplo, en el caso de \textit{Twitter} existen períodos del día que los usuarios comentan más, por lo tanto, en esos períodos aumentar la cantidad de recursos, y en los períodos que no comentan tanto, se podría disminuir la cantidad de recursos. 